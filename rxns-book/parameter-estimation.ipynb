{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Parameter estimation and rate law determination\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   The rate constants in rate laws generally must be determined from experiments\n",
    "\n",
    "-   We typically fit models to experimental data, and derive the rate constants from the fitted parameters\n",
    "\n",
    "-   There are two general types of fitting\n",
    "    -   linear regression\n",
    "        -   fitting models that are linear in the parameters\n",
    "    \n",
    "    -   nonlinear regression\n",
    "        -   fitting models that are nonlinear in the parameters\n",
    "\n",
    "-   In either case we want to estimate the value of the parameters in the model, and the uncertainty in the parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Linear regression review\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   In linear regression we fit a model that is linear in the parameters to some data.\n",
    "\n",
    "-   The model parameters may be directly useful, e.g. the slope of a line may be related to a rate constant, or we may use the model to derive something, e.g. the derivative at some value.\n",
    "\n",
    "-   A linear model is one like:\n",
    "\n",
    "\\begin{equation}\n",
    "y = p_0 + p_1 f_1(x) + p_2 f_2(x) + \\cdots\n",
    "\\end{equation}\n",
    "\n",
    "-   Here the parameters are $p_i$ and the model is linear in them.\n",
    "-   The functions $f_i(x)$ do not have to be linear\n",
    "-   Some examples are:\n",
    "    -   $ y = p_0 + p_1 x $ - a line\n",
    "    -   $ y = p_0 + p_1 x + p_2 x^2 $ - a parabola\n",
    "    -   $ y = p_0 + p_1 e^x $\n",
    "\n",
    "-   We will write these in the general matrix algebra form:\n",
    "\n",
    "\\begin{equation}\n",
    "\\bf{y} = \\bf{X} \\bf{p}\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{equation}\n",
    "\\bf{y} = \\left [\n",
    "\\begin{array}{c}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\\\\\n",
    "\\end{array}\n",
    "\\right ]\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\bf{X} = \\left [ \\begin{array}{cccc}\n",
    "f_n(x_1) & \\cdots & f_1(x_1) & 1 \\\\\n",
    "f_n(x_2) & \\cdots & f_1(x_2) & 1 \\\\\n",
    "\\vdots & \\vdots   & \\vdots   & \\vdots \\\\\n",
    "f_n(x_n) & \\cdots & f_1(x_n) & 1 \\\\\n",
    "\\end{array}\n",
    "\\right ]\n",
    "\\end{equation}\n",
    "\n",
    "and $ \\bf{p} = \\left [\\begin{array}{c}p_n \\\\ p_{n-1} \\\\ \\vdots \\\\ p_0 \\end{array} \\right ]  $\n",
    "\n",
    "-   The model will usually not fit data perfectly, so we modify the model to include the errors\n",
    "\n",
    "\\begin{equation}\n",
    "\\bf{y} = \\bf{X} \\bf{p} + \\bf{e}\n",
    "\\end{equation}\n",
    "\n",
    "-   We want the best estimate for **p**, which means we want the  **p** that minimizes the error in the least squares sense (that is the magnitude of the sum of squared errors is minimized)\n",
    "\n",
    "-   The best estimate for **p** is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\bf{p} = (\\bf{X}^T\\bf{X})^{-1}\\bf{X}^T \\bf{y}\n",
    "\\end{equation}\n",
    "\n",
    "-   There will typically be errors between the data and model with corresponding uncertainty in the estimated parameters\n",
    "\n",
    "-   We need to quantify the uncertainty to determine how important it is in reactor design\n",
    "\n",
    "Let us consider an example. We want to fit a line to the following data. The line has an equation $y = p_0 x + p_1$.\n",
    "\n",
    "-   Remember\n",
    "\n",
    "\\begin{equation}\n",
    "\\bf{p} = (\\bf{X}^T\\bf{X})^{-1}\\bf{X}^T \\bf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Here we solve a prototypical problem of fitting a line to some data. We are given some x and y data, and we want to fit a line.\n",
    "\n",
    "[numpy.column_stack](https://docs.scipy.org/doc/numpy/reference/generated/numpy.column_stack.html)\n",
    "\n",
    "-   You should always plot the fitted function over the data to visually assess the quality of the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slope is -0.3145221843003413 \n",
      "and intercept is 0.000624573378839699\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefe035e4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([0, 0.5, 1, 1.5, 2.0, 3.0, 4.0, 6.0, 10])\n",
    "y = np.array([0, -0.157, -0.315, -0.472, -0.629, -0.942, -1.255, -1.884, -3.147])\n",
    "\n",
    "X = np.column_stack([x, x**0])\n",
    "\n",
    "#  I find these intermediate variables make it easier to read\n",
    "XTX = np.matmul(X.T, X)\n",
    "XTy = np.dot(X.T, y)\n",
    "\n",
    "p = np.dot(np.linalg.inv(XTX), XTy)\n",
    "slope, intercept = p # note the order in X\n",
    "print('The slope is {0} \\nand intercept is {1}'.format(slope, intercept))\n",
    "\n",
    "# plot data and fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, np.dot(X, p), 'r--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.savefig('images/la-line-fit.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slope is -0.3130827080288672 \n",
      "and intercept is -0.0010957088645593416\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefbc606710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([0, 0.5, 1, 1.5, 2.0, 3.0, 4.0, 6.0, 10])\n",
    "y = np.array([0, -0.157, -0.315, -0.472, -0.629, -0.942, -1.255, -1.884, -3.147])\n",
    "\n",
    "X = np.column_stack([x**2, x, x**0])\n",
    "\n",
    "#  I find these intermediate variables make it easier to read\n",
    "XTX = np.dot(X.T, X)\n",
    "XTy = np.dot(X.T, y)\n",
    "\n",
    "p = np.dot(np.linalg.inv(XTX), XTy)\n",
    "test, slope, intercept = p # note the order in X\n",
    "print('The slope is {0} \\nand intercept is {1}'.format(slope, intercept))\n",
    "\n",
    "# plot data and fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, np.dot(X, p), 'r--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "# plt.savefig('images/la-line-fit.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo the last example by defining a function to calculate the summed squared error between the model and data, and use fmin to minimize the summed squared error. Show that you get the same parameters.\n",
    "\n",
    "-   The error in the fit is defined as: $\\bf{e} = \\bf{y} - \\bf{X}\\cdot \\bf{p}$\n",
    "\n",
    "-   We can compute the summed squared error as $SSE = \\bf{e} \\cdot \\bf{e}$\n",
    "-   We define $SST = \\sum (\\bf{y} - \\overline{y})^2 = (\\bf{y} - \\overline{y})\\cdot(\\bf{y} - \\overline{y})$\n",
    "\n",
    "-   We can use that to compute $R^2 = 1 - SSE/SST$ which roughly corresponds to the fraction of variance in the data explained by the model.\n",
    "\n",
    "-   Let us calculate the R^2 value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([-0.0006, -0.0004, -0.0011, -0.0008, -0.0006,  0.0009,  0.0025,\n",
      "        0.0025, -0.0024])\n",
      "R-squared = 0.9999972914903201 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "import pprint\n",
    "\n",
    "x = np.array([0, 0.5, 1, 1.5, 2.0, 3.0, 4.0, 6.0, 10])\n",
    "y = np.array([0, -0.157, -0.315, -0.472, -0.629, -0.942, -1.255, -1.884, -3.147])\n",
    "\n",
    "X = np.column_stack([x, x**0])\n",
    "\n",
    "#  I find these intermediate variables make it easier to read\n",
    "XTX = np.dot(X.T, X)\n",
    "XTy = np.dot(X.T, y)\n",
    "\n",
    "p = np.dot(np.linalg.inv(XTX), XTy)\n",
    "\n",
    "e = y - np.dot(X,p)\n",
    "pprint.pprint(e)\n",
    "\n",
    "SSE = np.dot(e, e)\n",
    "\n",
    "yb = y - np.mean(y)\n",
    "SST = np.dot(yb, yb)\n",
    "Rsq = 1 - SSE/SST\n",
    "\n",
    "print('R-squared = {0} '.format(Rsq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   The R^2 tells you how much of the variation in the data is explained by the model.\n",
    "    -   a value of 1 tells you all the variation is explained\n",
    "    -   values less than one means the model is incomplete in some way\n",
    "    -   Here the value is close to one, which suggests a good fit\n",
    "\n",
    "-   It is important to consider the uncertainty on the parameters\n",
    "\n",
    "-   pycse has a `regress` function for that\n",
    "    -   We specify a confidence level, typically 95%\n",
    "    -   &alpha; = (100 - %confidence level)/100\n",
    "    -   Let us apply that to the same data set\n",
    "\n",
    "[pycse.regress](https://www.google.com/#safe=off&q=pycse.regress)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slope is between [-0.315 -0.314] \n",
      "at the 95% confidence level\n",
      "The intercept is between [-0.0014  0.0027] \n",
      "at the 95% confidence level\n"
     ]
    }
   ],
   "source": [
    "from pycse import regress\n",
    "import numpy as np\n",
    "x = np.array([0, 0.5, 1, 1.5, 2.0, 3.0, 4.0, 6.0, 10])\n",
    "y = np.array([0, -0.157, -0.315, -0.472, -0.629, -0.942, -1.255, -1.884, -3.147])\n",
    "\n",
    "X = np.column_stack([x, x**0])\n",
    "\n",
    "# Choose 95% confidence level\n",
    "alpha = 1 - 0.95\n",
    "p, pint, se = regress(X, y, alpha)\n",
    "slope_interval, intercept_interval = pint\n",
    "\n",
    "print('The slope is between {0} \\n'\n",
    "      'at the 95% confidence level'.format(slope_interval))\n",
    "\n",
    "print('The intercept is between {0} \\n'\n",
    "      'at the 95% confidence level'.format(intercept_interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Note in this case that the second parameter includes 0\n",
    "    -   We cannot conclude that this parameter is significant.\n",
    "    -   A simpler model with the intercept fixed at 0 might be better\n",
    "\n",
    "-   The size of the confidence intervals depends on the number of data points, the number of estimated parameters, and the confidence level.\n",
    "\n",
    "Read the [regress](https://github.com/jkitchin/pycse/blob/master/pycse/PYCSE.py#L7) source code to learn how the confidence intervals are calculated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Applications in determining a rate constant and reaction order\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Rate constants and reaction orders are determined by using models that are fit to experimental data\n",
    "\n",
    "-   A common case is to monitor concentration vs. time in a constant volume, batch reactor\n",
    "\n",
    "-   We consider the disappearance of $A$\n",
    "\n",
    "-   From the mole balance we know:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{dN_A}{dt} = r_A V\n",
    "\\end{equation}\n",
    "\n",
    "-   Let us assume the rate law is of the form: $r_A = k C_A^\\alpha$ and a constant volume so that:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{dC_A}{dt} = -k C_A^\\alpha\n",
    "\\end{equation}\n",
    "\n",
    "-   Let us be loose with mathematics, rearrange the equation, and take the log of both sides.\n",
    "    -   By loose I mean we take logs of quantities that are not dimensionless\n",
    "\n",
    "\\begin{equation}\n",
    "\\ln(-\\frac{dC_A}{dt}) = \\ln{k} + \\alpha \\ln C_A\n",
    "\\end{equation}\n",
    "\n",
    "-   This suggests that if we could numerically compute $\\frac{dC_A}{dt}$ from our data of $C_A(t)$ then a plot of the log of the negative derivative vs the log of concentration would have\n",
    "    -   an intercept equal to the log of the rate constant, $k$\n",
    "    -   and a slope equal to the reaction order $\\alpha$\n",
    "\n",
    "-   Given the following data, determine the reaction order in A and the rate constant with 95% confidence intervals.\n",
    "\n",
    "<table id=\"orgfd5ae74\" border=\"2\" cellspacing=\"0\" cellpadding=\"6\" rules=\"groups\" frame=\"hsides\">\n",
    "\n",
    "\n",
    "<colgroup>\n",
    "<col  class=\"org-right\" />\n",
    "\n",
    "<col  class=\"org-right\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr>\n",
    "<th scope=\"col\" class=\"org-right\">time (min)</th>\n",
    "<th scope=\"col\" class=\"org-right\">C\\_A (mol/L)</th>\n",
    "</tr>\n",
    "</thead>\n",
    "\n",
    "<tbody>\n",
    "<tr>\n",
    "<td class=\"org-right\">0</td>\n",
    "<td class=\"org-right\">0.0500</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-right\">50</td>\n",
    "<td class=\"org-right\">0.0380</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-right\">100</td>\n",
    "<td class=\"org-right\">0.0306</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-right\">150</td>\n",
    "<td class=\"org-right\">0.0256</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-right\">200</td>\n",
    "<td class=\"org-right\">0.0222</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-right\">250</td>\n",
    "<td class=\"org-right\">0.0195</td>\n",
    "</tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "<td class=\"org-right\">300</td>\n",
    "<td class=\"org-right\">0.0174</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "-   We will use the `pycse.deriv` function to numerically compute centered 2-point finite difference approximations to the derivatives\n",
    "-   This works best when the $x$ points are evenly spaced, and they should be monotically increasing or decreasing\n",
    "\n",
    "[pycse.deriv](https://www.google.com/#safe=off&q=pycse.deriv)\n",
    "\n",
    "Read the [deriv](https://github.com/jkitchin/pycse/blob/master/pycse/PYCSE.py#L182) source code to learn how the derivatives are approximated, and what options are available.\n",
    "\n",
    "-   Note that we are actually using the data in table [tab-data>](tab-data>)in this code block!\n",
    "\n",
    "-   We do not have to type the data in ourselves.\n",
    "\n",
    "-   This causes some false reporting in pyflakes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we need to convert the list of numbers to a numpy array so we can do the analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-41d92eff1f85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# data will be a 2d list, which we convert to an array here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# column 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mCa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# column 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)  # alternate approach to printing accuracy\n",
    "from pycse import deriv, regress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data will be a 2d list, which we convert to an array here\n",
    "data = np.array(data)\n",
    "t = data[:, 0]   # column 0\n",
    "Ca = data[:, 1]  # column 1\n",
    "\n",
    "# calculate numerical derivatives\n",
    "dCadt = deriv(t, Ca)\n",
    "\n",
    "# do the transformation\n",
    "x = np.log(Ca)\n",
    "y = np.log(-dCadt)\n",
    "\n",
    "# setup and do the regression\n",
    "# column of ones and x:  y = b + mx\n",
    "X = np.column_stack([x**0, x])\n",
    "\n",
    "p, pint, se = regress(X, y, 0.05)\n",
    "\n",
    "intercept_range = pint[0]\n",
    "alpha_range = pint[1]\n",
    "\n",
    "k = np.exp(intercept_range)\n",
    "\n",
    "print('alpha = {0} at the 95% confidence level'.format(alpha_range))\n",
    "print('k = {0} at the 95% confidence level'.format(k))\n",
    "\n",
    "# always visually inspect the fit\n",
    "plt.plot(x, y,'ko ')\n",
    "plt.plot(x, np.dot(X, p))\n",
    "plt.xlabel('$\\ln(C_A)$')\n",
    "plt.ylabel('$\\ln(-dC_A/dt)$')\n",
    "plt.savefig('images/regression-rate.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./images/regression-rate.png)\n",
    "\n",
    "-   You can see there is a reasonably large range of values for the rate constant and reaction order (although the confidence interval does not contain zero)\n",
    "\n",
    "-   The fit looks ok, but you can see the errors are not exactly random\n",
    "    -   There seems to be systematic trends in a sigmoidal shape of the data\n",
    "    -   That suggests small inadequacy in the model\n",
    "\n",
    "-   Let us examine some methods of evaluating the quality of fit\n",
    "\n",
    "-   First we examine the residuals, or the errors between the data and the model.\n",
    "\n",
    "-   In a good fit, these will be randomly distributed\n",
    "\n",
    "-   In a less good fit, there will be trends\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "from pycse import deriv, regress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data will be a 2d list, which we convert to an array here\n",
    "data = np.array(data)\n",
    "t = data[:, 0]\n",
    "Ca = data[:, 1]\n",
    "\n",
    "# calculate numerical derivatives\n",
    "dCadt = deriv(t, Ca)\n",
    "\n",
    "# do the transformation\n",
    "x = np.log(Ca)\n",
    "y = np.log(-dCadt)\n",
    "\n",
    "# setup and do the regression\n",
    "# column of ones and x:  y = b + mx\n",
    "X = np.column_stack([x**0, x])\n",
    "\n",
    "p, pint, se = regress(X, y, 0.05)\n",
    "\n",
    "residuals = y - np.dot(X, p)\n",
    "\n",
    "# always visually inspect the fit\n",
    "plt.plot(x, residuals, 'ko-')\n",
    "plt.xlabel('$\\ln(C_A)$')\n",
    "plt.ylabel('residuals')\n",
    "plt.savefig('images/regression-residuals.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./images/regression-residuals.png)\n",
    "\n",
    "-   You can see there are trends in this data\n",
    "    -   That means the model may not be complete\n",
    "\n",
    "-   There is uncertainty in the data\n",
    "    -   In each concentration measurement there is uncertainty in the time and value of concentration\n",
    "    -   You need more data to reduce the uncertainty\n",
    "    -   You may also need better data to reduce the uncertainty\n",
    "\n",
    "-   Derivatives tend to *magnify* errors in data\n",
    "    -   The method we used to fit the data contributed to the uncertainty\n",
    "\n",
    "-   We also *nonlinearly* transformed the errors by taking logs and exp of the data and results, which may have skewed the confidence limits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Hybrid methods for data analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Numerical differentiation is noisy, but does the least amount of data manipulation, e.g. smoothing\n",
    "\n",
    "-   Let us consider some hybrid approaches\n",
    "\n",
    "-   The first hybrid method is to fit a polynomial to the Ca(t) data, and then analytically differentiate the polynomial\n",
    "\n",
    "-   You must use some judgment about what order polynomial to fit\n",
    "    -   Judgment comes from experience\n",
    "\n",
    "[numpy.polyfit](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html)  Fit a polynomial to data\n",
    "\n",
    "[numpy.polyder](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyder.html)  Get the derivative of a polynomial\n",
    "\n",
    "[numpy.polyval](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyval.html)  Evaluate a polynomial at some data points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "from pycse import regress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data will be a 2d list, which we convert to an array here\n",
    "data = np.array(data)\n",
    "t = data[:, 0]\n",
    "Ca = data[:, 1]\n",
    "\n",
    "pCa = np.polyfit(t, Ca, 4)\n",
    "\n",
    "fCa = np.polyval(pCa, t)\n",
    "\n",
    "print('Summed squared error = {}'.format(sum(fCa - Ca)**2))\n",
    "\n",
    "# always visually inspect the fit\n",
    "plt.plot(t, Ca, 'ko ')\n",
    "plt.plot(t, fCa)\n",
    "plt.xlabel('$t$ (min)')\n",
    "plt.ylabel('$C_A$ (mol/L)')\n",
    "plt.title('Polynomial fit to the data')\n",
    "plt.savefig('images/polyfit-1.png')\n",
    "\n",
    "# [[./images/polyfit-1.png]]\n",
    "\n",
    "# get the derivative\n",
    "dCadt = np.polyval(np.polyder(pCa), t)\n",
    "\n",
    "# Construct the data we want to fit\n",
    "# ln(-dCa/dt) = alpha ln(Ca) + ln(k)\n",
    "x = np.log(Ca)\n",
    "y = np.log(-dCadt)\n",
    "\n",
    "X = np.column_stack([x**0, x])\n",
    "p, pint, se = regress(X, y, 0.05)\n",
    "\n",
    "intercept_range = pint[0]\n",
    "alpha_range = pint[1]\n",
    "\n",
    "k = np.exp(intercept_range)\n",
    "\n",
    "print('alpha = {} at the 95% confidence level'.format(alpha_range))\n",
    "print('k = {0} at the 95% confidence level'.format(k))\n",
    "\n",
    "# always visually inspect the fit\n",
    "plt.figure()\n",
    "plt.plot(x, y, 'ko ')\n",
    "plt.plot(x, np.dot(X, p))\n",
    "plt.xlabel('$\\ln(C_A)$')\n",
    "plt.ylabel('$\\ln(-dC_A/dt)$')\n",
    "plt.savefig('images/poly-regression-rate.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./images/poly-regression-rate.png)\n",
    "\n",
    "-   Note the confidence intervals are tighter\n",
    "-   That is because the polynomial fitting smooths some of the errors out\n",
    "-   We still have nonlinearly transformed errors which may skew the confidence intervals\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Nonlinear regression review\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Nonlinear models are abundant in reaction engineering\n",
    "    -   $r = k C_A^n $ is linear in the $k$ parameter, and nonlinear in $n$\n",
    "\n",
    "-   Nonlinear fitting is essentially a non-linear optimization problem\n",
    "\n",
    "-   Unlike linear regression, where we directly compute the parameters using matrix algebra, we have to provide an initial guess and iterate to the solution\n",
    "\n",
    "-   Similar to using fsolve, we must define a function of the model\n",
    "    -   The function takes an independent variable, and parameters, f(x,a,b,&#x2026;)\n",
    "    -   The function should return a value of $y$ for every value of $x$\n",
    "    -   i.e. it should be vectorized\n",
    "\n",
    "-   It is possible to formulate these problems as nonlinear minimization of summed squared errors. See [this example](http://jkitchin.github.io/blog/2013/02/18/Nonlinear-curve-fitting/).\n",
    "\n",
    "-   The function `scipy.optimize.curve_fit` provides nonlinear fitting of models (functions) to data.\n",
    "\n",
    "[scipy.optimize.curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html)\n",
    "\n",
    "-   Here is an example usage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 1.3275314145379786 and b=0.026461556970080666\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBRERiVEoiIhIzP8BWFF0mJCEbigAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefb4336cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "x = np.array([0.5, 0.387, 0.24, 0.136, 0.04, 0.011])\n",
    "y = np.array([1.255, 1.25, 1.189, 1.124, 0.783, 0.402])\n",
    "\n",
    "# this is the function we want to fit to our data\n",
    "def func(x, a, b):\n",
    "    'nonlinear function in a and b to fit to data'\n",
    "    return a * x / (b + x)\n",
    "\n",
    "initial_guess = [1.2, 0.03]\n",
    "\n",
    "pars, pcov = curve_fit(func, x, y, p0=initial_guess)\n",
    "\n",
    "a,b = pars\n",
    "print('a = {0} and b={1}'.format(a,b))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x,y,'bo ')\n",
    "xfit = np.linspace(min(x), max(x))\n",
    "yfit = func(xfit, *pars)\n",
    "plt.plot(xfit,yfit,'b-')\n",
    "plt.legend(['data','fit'],loc='best')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.savefig('images/nonlin-curve-fit.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./images/nonlin-curve-fit.png)\n",
    "\n",
    "-   Again, you should always visually inspect the fit\n",
    "\n",
    "Practice: Repeat this last example by creating a function that calculates the summed squared errors between a model function and the data. Use fmin to find the parameters that minimizes the summed squared error.\n",
    "\n",
    "-   We also need to estimate uncertainties in nonlinear parameters\n",
    "\n",
    "-   `pycse` provides a function for this: `nlinfit`.\n",
    "\n",
    "[pycse.nlinfit](https://www.google.com/#safe=off&q=pycse.nlinfit)\n",
    "\n",
    "Read the [nlinfit](https://github.com/jkitchin/pycse/blob/master/pycse/PYCSE.py#L53) source code to see how the confidence intervals are computed\n",
    "\n",
    "Here is an example usage of nlinfit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% confidence interval on a is [ 1.301  1.355]\n",
      "The 95% confidence interval on b is [ 0.024  0.029]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "from pycse import nlinfit\n",
    "\n",
    "x = np.array([0.5, 0.387, 0.24, 0.136, 0.04, 0.011])\n",
    "y = np.array([1.255, 1.25, 1.189, 1.124, 0.783, 0.402])\n",
    "\n",
    "\n",
    "def func(x, a, b):\n",
    "    'nonlinear function in a and b to fit to data'\n",
    "    return a * x / (b + x)\n",
    "\n",
    "initial_guess = [1.2, 0.03]\n",
    "alpha = 0.05\n",
    "pars, pint, se = nlinfit(func, x, y, initial_guess, alpha)\n",
    "\n",
    "aint, bint = np.array(pint)\n",
    "print('The 95% confidence interval on a is {0}'.format(aint))\n",
    "print('The 95% confidence interval on b is {0}'.format(bint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Here the two intervals are relatively small, and do not include zero, suggesting both parameters are significant.\n",
    "\n",
    "-   More importantly, the errors are not skewed by a nonlinear transformation.\n",
    "\n",
    "-   Note you have to provide an initial guess.\n",
    "    -   This will not always be easy to guess.\n",
    "    -   There may be more than one minimum in the fit also, so different guesses may give different parameters.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "132px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
